{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Feature Engineering & Dataset Merging\n",
    "\n",
    "## Output Files:\n",
    "1. `clustering_features.csv` - Model 1 (Behavior Clustering)\n",
    "2. `pace_features.csv` - Model 3 (Pace Analysis)\n",
    "3. `advice_context.csv` - Model 2 (Advice Generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment Ready!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "INTERIM_DIR = '../data/interim'\n",
    "PROCESSED_DIR = '../data/processed'\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. LOAD CLEANED DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOADING ALL CLEANED DATASETS\n",
      "============================================================\n",
      "\n",
      "üìÇ Loaded Files:\n",
      "  Users: 31 rows\n",
      "  Trackings: 101,689 rows\n",
      "  Submissions: 2,262 rows\n",
      "  Exam Results: 17,438 rows\n",
      "  Completions: 1,032 rows\n",
      "  Journeys: 176 rows\n",
      "  Tutorials: 9,682 rows\n",
      "  Exam Registrations: 16,759 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOADING ALL CLEANED DATASETS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df_users = pd.read_csv(os.path.join(INTERIM_DIR, 'users_clean.csv'))\n",
    "df_trackings = pd.read_csv(os.path.join(INTERIM_DIR, 'trackings_clean.csv'), \n",
    "                          parse_dates=['last_viewed', 'first_opened_at', 'completed_at'])\n",
    "df_submissions = pd.read_csv(os.path.join(INTERIM_DIR, 'submissions_clean.csv'), \n",
    "                            parse_dates=['created_at'])\n",
    "df_exam_res = pd.read_csv(os.path.join(INTERIM_DIR, 'exam_results_clean.csv'), \n",
    "                         parse_dates=['created_at'])\n",
    "df_completions = pd.read_csv(os.path.join(INTERIM_DIR, 'completions_clean.csv'), \n",
    "                            parse_dates=['created_at', 'last_enrolled_at'])\n",
    "df_journeys = pd.read_csv(os.path.join(INTERIM_DIR, 'journeys_clean.csv'))\n",
    "df_tutorials = pd.read_csv(os.path.join(INTERIM_DIR, 'tutorials_clean.csv'))\n",
    "df_exam_reg = pd.read_csv(os.path.join(INTERIM_DIR, 'exam_registrations_clean.csv'), \n",
    "                         parse_dates=['created_at', 'exam_finished_at'])\n",
    "\n",
    "print(\"\\nüìÇ Loaded Files:\")\n",
    "print(f\"  Users: {len(df_users):,} rows\")\n",
    "print(f\"  Trackings: {len(df_trackings):,} rows\")\n",
    "print(f\"  Submissions: {len(df_submissions):,} rows\")\n",
    "print(f\"  Exam Results: {len(df_exam_res):,} rows\")\n",
    "print(f\"  Completions: {len(df_completions):,} rows\")\n",
    "print(f\"  Journeys: {len(df_journeys):,} rows\")\n",
    "print(f\"  Tutorials: {len(df_tutorials):,} rows\")\n",
    "print(f\"  Exam Registrations: {len(df_exam_reg):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. DATASET 1: CLUSTERING FEATURES (MODEL 1)\n",
    "\n",
    "**Required Features**:\n",
    "1. `avg_study_hour` - From trackings.last_viewed\n",
    "2. `study_consistency_std` - Std of study gaps\n",
    "3. `completion_speed` - study_duration / hours_to_study\n",
    "4. `avg_exam_score` - From exam_results\n",
    "5. `submission_fail_rate` - From submissions.status\n",
    "6. `retry_count` - From completions.enrolling_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUILDING DATASET 1: CLUSTERING FEATURES\n",
      "============================================================\n",
      "\n",
      "üîß Aggregating Trackings...\n",
      "   ‚úì Tracking features: (2013, 9)\n",
      "   ‚úì Created: avg_study_hour, study_consistency_std, study_consistency_ratio\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BUILDING DATASET 1: CLUSTERING FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === 2.1 Aggregate Trackings ===\n",
    "print(\"\\nüîß Aggregating Trackings...\")\n",
    "\n",
    "tracking_agg = df_trackings.groupby(['developer_id', 'journey_id']).agg({\n",
    "    'tutorial_id': 'count',\n",
    "    'last_viewed': ['min', 'max'],\n",
    "    'completed_at': 'count',\n",
    "}).reset_index()\n",
    "\n",
    "tracking_agg.columns = ['developer_id', 'journey_id', 'total_modules_viewed', \n",
    "                        'first_activity', 'last_activity', 'completed_modules']\n",
    "\n",
    "# Feature 1: avg_study_hour\n",
    "temp_hours = df_trackings.dropna(subset=['last_viewed']).copy()\n",
    "temp_hours['hour'] = temp_hours['last_viewed'].dt.hour\n",
    "hour_agg = temp_hours.groupby(['developer_id', 'journey_id'])['hour'].mean().reset_index()\n",
    "hour_agg.columns = ['developer_id', 'journey_id', 'avg_study_hour']\n",
    "tracking_agg = tracking_agg.merge(hour_agg, on=['developer_id', 'journey_id'], how='left')\n",
    "\n",
    "# Feature 2: study_consistency_std (as per design doc)\n",
    "temp_dates = df_trackings.dropna(subset=['last_viewed']).copy()\n",
    "temp_dates['date'] = temp_dates['last_viewed'].dt.date\n",
    "temp_dates = temp_dates.sort_values(['developer_id', 'journey_id', 'date'])\n",
    "\n",
    "def calculate_consistency_std(group):\n",
    "    unique_dates = sorted(group['date'].unique())\n",
    "    if len(unique_dates) <= 1:\n",
    "        return 0\n",
    "    gaps = [(unique_dates[i] - unique_dates[i-1]).days for i in range(1, len(unique_dates))]\n",
    "    return np.std(gaps) if gaps else 0\n",
    "\n",
    "consistency = temp_dates.groupby(['developer_id', 'journey_id']).apply(\n",
    "    calculate_consistency_std\n",
    ").reset_index()\n",
    "consistency.columns = ['developer_id', 'journey_id', 'study_consistency_std']\n",
    "tracking_agg = tracking_agg.merge(consistency, on=['developer_id', 'journey_id'], how='left')\n",
    "\n",
    "# Also keep ratio for additional insight\n",
    "temp_dates_ratio = df_trackings.dropna(subset=['last_viewed']).copy()\n",
    "temp_dates_ratio['date'] = temp_dates_ratio['last_viewed'].dt.date\n",
    "consistency_ratio = temp_dates_ratio.groupby(['developer_id', 'journey_id'])['date'].apply(\n",
    "    lambda x: x.nunique() / ((x.max() - x.min()).days + 1) if (x.max() - x.min()).days > 0 else 1\n",
    ").reset_index()\n",
    "consistency_ratio.columns = ['developer_id', 'journey_id', 'study_consistency_ratio']\n",
    "tracking_agg = tracking_agg.merge(consistency_ratio, on=['developer_id', 'journey_id'], how='left')\n",
    "\n",
    "print(f\"   ‚úì Tracking features: {tracking_agg.shape}\")\n",
    "print(f\"   ‚úì Created: avg_study_hour, study_consistency_std, study_consistency_ratio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Aggregating Submissions...\n",
      "   ‚úì Submission features: (549, 9)\n"
     ]
    }
   ],
   "source": [
    "# === 2.2 Aggregate Submissions ===\n",
    "print(\"\\nüîß Aggregating Submissions...\")\n",
    "\n",
    "df_submissions['is_passed'] = df_submissions['status'].apply(\n",
    "    lambda x: 1 if x in ['passed', 'approved'] else 0 if pd.notna(x) else np.nan\n",
    ")\n",
    "\n",
    "submission_agg = df_submissions.groupby(['submitter_id', 'journey_id']).agg({\n",
    "    'rating': 'mean',\n",
    "    'is_passed': ['mean', 'sum', 'count'],\n",
    "    'submission_duration': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "submission_agg.columns = ['developer_id', 'journey_id', 'avg_submission_rating', \n",
    "                          'submission_pass_rate', 'submissions_passed', 'total_submissions',\n",
    "                          'avg_submission_duration']\n",
    "\n",
    "submission_agg['submission_fail_count'] = submission_agg['total_submissions'] - submission_agg['submissions_passed']\n",
    "submission_agg['submission_fail_rate'] = submission_agg['submission_fail_count'] / submission_agg['total_submissions']\n",
    "\n",
    "# Handle division by zero\n",
    "submission_agg['submission_fail_rate'] = submission_agg['submission_fail_rate'].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "print(f\"   ‚úì Submission features: {submission_agg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Aggregating Exam Results...\n",
      "   ‚úì Exam features: (1352, 7)\n"
     ]
    }
   ],
   "source": [
    "# === 2.3 Aggregate Exam Results ===\n",
    "print(\"\\nüîß Aggregating Exam Results...\")\n",
    "\n",
    "exam_full = df_exam_res.merge(df_exam_reg[['id', 'examinees_id', 'tutorial_id']], \n",
    "                               left_on='exam_registration_id', right_on='id', how='left')\n",
    "exam_full = exam_full.merge(df_tutorials[['id', 'developer_journey_id']], \n",
    "                            left_on='tutorial_id', right_on='id', how='left', suffixes=('', '_tutorial'))\n",
    "\n",
    "exam_agg = exam_full.groupby(['examinees_id', 'developer_journey_id']).agg({\n",
    "    'score': 'mean',\n",
    "    'is_passed': ['mean', 'sum', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "exam_agg.columns = ['developer_id', 'journey_id', 'avg_exam_score', \n",
    "                    'exam_pass_rate', 'exams_passed', 'total_exams']\n",
    "exam_agg['exam_fail_count'] = exam_agg['total_exams'] - exam_agg['exams_passed']\n",
    "\n",
    "print(f\"   ‚úì Exam features: {exam_agg.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Processing Completions...\n",
      "   ‚úì Completion features: (1032, 5)\n"
     ]
    }
   ],
   "source": [
    "# === 2.4 Process Completions ===\n",
    "print(\"\\nüîß Processing Completions...\")\n",
    "\n",
    "completion_features = df_completions[['user_id', 'journey_id', 'study_duration', \n",
    "                                       'enrolling_times', 'avg_submission_rating']].copy()\n",
    "completion_features.columns = ['developer_id', 'journey_id', 'study_duration', \n",
    "                               'retry_count', 'completion_avg_rating']\n",
    "\n",
    "print(f\"   ‚úì Completion features: {completion_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Merging all features...\n",
      "   ‚úì Merged dataset shape: (2013, 28)\n",
      "   ‚úì Unique users: 31\n",
      "   ‚úì Unique journeys: 181\n"
     ]
    }
   ],
   "source": [
    "# === 2.5 Merge All Features ===\n",
    "print(\"\\nüîß Merging all features...\")\n",
    "\n",
    "clustering_df = tracking_agg.copy()\n",
    "clustering_df = clustering_df.merge(submission_agg, on=['developer_id', 'journey_id'], how='left')\n",
    "clustering_df = clustering_df.merge(exam_agg, on=['developer_id', 'journey_id'], how='left')\n",
    "clustering_df = clustering_df.merge(completion_features, on=['developer_id', 'journey_id'], how='left')\n",
    "clustering_df = clustering_df.merge(df_journeys[['id', 'name', 'difficulty', 'hours_to_study']], \n",
    "                                   left_on='journey_id', right_on='id', how='left', suffixes=('', '_journey'))\n",
    "\n",
    "print(f\"   ‚úì Merged dataset shape: {clustering_df.shape}\")\n",
    "print(f\"   ‚úì Unique users: {clustering_df['developer_id'].nunique()}\")\n",
    "print(f\"   ‚úì Unique journeys: {clustering_df['journey_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating derived features...\n",
      "‚úÖ Derived features created (infinity-safe)\n",
      "   completion_speed range: 0.00 - 10.00\n"
     ]
    }
   ],
   "source": [
    "# === 2.6 Feature Engineering - Derived Features ===\n",
    "print(\"\\nüîß Creating derived features...\")\n",
    "\n",
    "# 1. Completion speed (infinity-safe)\n",
    "clustering_df['completion_speed'] = np.where(\n",
    "    (clustering_df['hours_to_study'] > 0) & (clustering_df['study_duration'].notna()),\n",
    "    clustering_df['study_duration'] / clustering_df['hours_to_study'],\n",
    "    np.nan\n",
    ")\n",
    "clustering_df['completion_speed'] = clustering_df['completion_speed'].clip(upper=10)\n",
    "\n",
    "# 2. Performance score (composite)\n",
    "clustering_df['performance_score'] = (\n",
    "    clustering_df['avg_exam_score'].fillna(0) * 0.4 + \n",
    "    clustering_df['avg_submission_rating'].fillna(0) * 20 * 0.6\n",
    ")\n",
    "\n",
    "# 3. Struggle score (composite)\n",
    "clustering_df['struggle_score'] = (\n",
    "    clustering_df['exam_fail_count'].fillna(0) + \n",
    "    clustering_df['submission_fail_count'].fillna(0) * 2\n",
    ")\n",
    "\n",
    "# 4. Speed Category Binning\n",
    "clustering_df['speed_category'] = pd.cut(\n",
    "    clustering_df['completion_speed'],\n",
    "    bins=[0, 0.7, 1.3, float('inf')],\n",
    "    labels=['Fast (< 70%)', 'Normal (70-130%)', 'Slow (> 130%)']\n",
    ")\n",
    "\n",
    "# 5. Study Time Slot Binning\n",
    "clustering_df['study_time_slot'] = pd.cut(\n",
    "    clustering_df['avg_study_hour'], \n",
    "    bins=[0, 6, 12, 18, 24], \n",
    "    labels=['Night (0-6)', 'Morning (6-12)', 'Afternoon (12-18)', 'Evening (18-24)']\n",
    ")\n",
    "\n",
    "# 6. Performance Level Binning\n",
    "clustering_df['performance_level'] = pd.cut(\n",
    "    clustering_df['performance_score'],\n",
    "    bins=[0, 40, 70, 100],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Derived features created (infinity-safe)\")\n",
    "print(f\"   completion_speed range: {clustering_df['completion_speed'].min():.2f} - {clustering_df['completion_speed'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Comprehensive NaN handling for ALL columns...\n",
      "   ‚úì Removed 5 rows with missing journey info\n",
      "\n",
      "   üîß Filling count columns with 0...\n",
      "      submission_fail_count: filled 1459 NaN ‚Üí 0\n",
      "      submissions_passed: filled 1459 NaN ‚Üí 0\n",
      "      total_submissions: filled 1459 NaN ‚Üí 0\n",
      "      exams_passed: filled 661 NaN ‚Üí 0\n",
      "      total_exams: filled 661 NaN ‚Üí 0\n",
      "      exam_fail_count: filled 661 NaN ‚Üí 0\n",
      "      retry_count: filled 976 NaN ‚Üí 0\n",
      "\n",
      "   üîß Filling rate columns with 0...\n",
      "      submission_pass_rate: filled 1459 NaN ‚Üí 0\n",
      "      submission_fail_rate: filled 1459 NaN ‚Üí 0\n",
      "      exam_pass_rate: filled 661 NaN ‚Üí 0\n",
      "\n",
      "   üîß Filling rating columns with median...\n",
      "      avg_submission_rating: filled 1459 NaN ‚Üí median (2.62)\n",
      "      avg_submission_duration: filled 1459 NaN ‚Üí median (180.00)\n",
      "      completion_avg_rating: filled 976 NaN ‚Üí median (4.00)\n",
      "      study_duration: filled 976 NaN ‚Üí median (16.00)\n",
      "\n",
      "   üîß Filling other numeric columns...\n",
      "      avg_exam_score: filled 661 NaN ‚Üí median (83.85)\n",
      "      completion_speed: filled 983 NaN ‚Üí median (0.56)\n",
      "\n",
      "   üîß Filling categorical columns...\n",
      "      study_time_slot: filled 2 NaN ‚Üí mode ('Afternoon (12-18)')\n",
      "      performance_level: filled 548 NaN ‚Üí mode ('Low')\n",
      "      speed_category: filled 1142 NaN ‚Üí mode ('Fast (< 70%)')\n"
     ]
    }
   ],
   "source": [
    "# === 2.7 Comprehensive NaN Handling ===\n",
    "print(\"\\nüîß Comprehensive NaN handling for ALL columns...\")\n",
    "\n",
    "# A. Remove rows with missing journey info\n",
    "rows_before = len(clustering_df)\n",
    "clustering_df = clustering_df.dropna(subset=['id', 'name'])\n",
    "rows_after = len(clustering_df)\n",
    "print(f\"   ‚úì Removed {rows_before - rows_after} rows with missing journey info\")\n",
    "\n",
    "# B. Count/failure columns: fill with 0\n",
    "print(\"\\n   üîß Filling count columns with 0...\")\n",
    "count_cols = [\n",
    "    'submission_fail_count', 'submissions_passed', 'total_submissions',\n",
    "    'exams_passed', 'total_exams', 'exam_fail_count',\n",
    "    'retry_count', 'completed_modules', 'total_modules_viewed'\n",
    "]\n",
    "\n",
    "for col in count_cols:\n",
    "    if col in clustering_df.columns:\n",
    "        nan_before = clustering_df[col].isnull().sum()\n",
    "        if nan_before > 0:\n",
    "            clustering_df[col] = clustering_df[col].fillna(0)\n",
    "            print(f\"      {col}: filled {nan_before} NaN ‚Üí 0\")\n",
    "\n",
    "# C. Rate columns: fill with 0\n",
    "print(\"\\n   üîß Filling rate columns with 0...\")\n",
    "rate_cols = ['submission_pass_rate', 'submission_fail_rate', 'exam_pass_rate']\n",
    "\n",
    "for col in rate_cols:\n",
    "    if col in clustering_df.columns:\n",
    "        nan_before = clustering_df[col].isnull().sum()\n",
    "        if nan_before > 0:\n",
    "            clustering_df[col] = clustering_df[col].fillna(0)\n",
    "            print(f\"      {col}: filled {nan_before} NaN ‚Üí 0\")\n",
    "\n",
    "# D. Rating/duration columns: fill with median\n",
    "print(\"\\n   üîß Filling rating columns with median...\")\n",
    "duration_rating_cols = [\n",
    "    'avg_submission_rating', 'avg_submission_duration',\n",
    "    'completion_avg_rating', 'study_duration'\n",
    "]\n",
    "\n",
    "for col in duration_rating_cols:\n",
    "    if col in clustering_df.columns:\n",
    "        nan_before = clustering_df[col].isnull().sum()\n",
    "        if nan_before > 0:\n",
    "            if clustering_df[col].notna().any():\n",
    "                fill_value = clustering_df[col].median()\n",
    "                clustering_df[col] = clustering_df[col].fillna(fill_value)\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí median ({fill_value:.2f})\")\n",
    "            else:\n",
    "                clustering_df[col] = clustering_df[col].fillna(0)\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí 0 (no valid data)\")\n",
    "\n",
    "# E. Other numeric columns\n",
    "print(\"\\n   üîß Filling other numeric columns...\")\n",
    "other_numeric_cols = [\n",
    "    'avg_exam_score', 'avg_study_hour', 'study_consistency_std', \n",
    "    'study_consistency_ratio', 'performance_score', 'struggle_score',\n",
    "    'completion_speed', 'difficulty', 'hours_to_study'\n",
    "]\n",
    "\n",
    "for col in other_numeric_cols:\n",
    "    if col in clustering_df.columns:\n",
    "        nan_before = clustering_df[col].isnull().sum()\n",
    "        if nan_before > 0:\n",
    "            if clustering_df[col].notna().any():\n",
    "                fill_value = clustering_df[col].median()\n",
    "                clustering_df[col] = clustering_df[col].fillna(fill_value)\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí median ({fill_value:.2f})\")\n",
    "            else:\n",
    "                clustering_df[col] = clustering_df[col].fillna(0)\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí 0\")\n",
    "\n",
    "# F. Categorical columns  \n",
    "print(\"\\n   üîß Filling categorical columns...\")\n",
    "categorical_cols = ['study_time_slot', 'performance_level', 'speed_category']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in clustering_df.columns:\n",
    "        nan_before = clustering_df[col].isnull().sum()\n",
    "        if nan_before > 0:\n",
    "            mode_values = clustering_df[col].dropna().mode()\n",
    "            if not mode_values.empty:\n",
    "                fill_value = mode_values[0]\n",
    "                clustering_df[col] = clustering_df[col].fillna(fill_value)\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí mode ('{fill_value}')\")\n",
    "            else:\n",
    "                clustering_df[col] = clustering_df[col].fillna('Unknown')\n",
    "                print(f\"      {col}: filled {nan_before} NaN ‚Üí 'Unknown'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL VALIDATION - CLUSTERING DATASET\n",
      "============================================================\n",
      "\n",
      "üîç Checking 6 core clustering features:\n",
      "   ‚úÖ avg_study_hour: Clean\n",
      "   ‚úÖ study_consistency_std: Clean\n",
      "   ‚úÖ completion_speed: Clean\n",
      "   ‚úÖ avg_exam_score: Clean\n",
      "   ‚úÖ submission_fail_rate: Clean\n",
      "   ‚úÖ retry_count: Clean\n",
      "\n",
      "üéâ ALL CORE FEATURES ARE READY FOR CLUSTERING!\n",
      "   Dataset shape: (2008, 34)\n",
      "\n",
      "üìä Descriptive statistics for core features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_study_hour</th>\n",
       "      <th>study_consistency_std</th>\n",
       "      <th>completion_speed</th>\n",
       "      <th>avg_exam_score</th>\n",
       "      <th>submission_fail_rate</th>\n",
       "      <th>retry_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2008.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.815199</td>\n",
       "      <td>63.583960</td>\n",
       "      <td>1.076897</td>\n",
       "      <td>81.635622</td>\n",
       "      <td>0.273406</td>\n",
       "      <td>0.637948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.901394</td>\n",
       "      <td>102.130422</td>\n",
       "      <td>1.932933</td>\n",
       "      <td>12.886300</td>\n",
       "      <td>0.445819</td>\n",
       "      <td>0.776392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.474080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>79.294201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.919643</td>\n",
       "      <td>5.857738</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>83.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.387234</td>\n",
       "      <td>97.251981</td>\n",
       "      <td>0.590217</td>\n",
       "      <td>88.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>761.817709</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       avg_study_hour  study_consistency_std  completion_speed  \\\n",
       "count     2008.000000            2008.000000       2008.000000   \n",
       "mean        13.815199              63.583960          1.076897   \n",
       "std          3.901394             102.130422          1.932933   \n",
       "min          0.000000               0.000000          0.000000   \n",
       "25%         11.474080               0.000000          0.533333   \n",
       "50%         13.919643               5.857738          0.560000   \n",
       "75%         16.387234              97.251981          0.590217   \n",
       "max         23.000000             761.817709         10.000000   \n",
       "\n",
       "       avg_exam_score  submission_fail_rate  retry_count  \n",
       "count     2008.000000           2008.000000  2008.000000  \n",
       "mean        81.635622              0.273406     0.637948  \n",
       "std         12.886300              0.445819     0.776392  \n",
       "min          0.000000              0.000000     0.000000  \n",
       "25%         79.294201              0.000000     0.000000  \n",
       "50%         83.846154              0.000000     1.000000  \n",
       "75%         88.571429              1.000000     1.000000  \n",
       "max        100.000000              1.000000     9.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç DUPLICATE CHECK:\n",
      "   ‚úÖ No duplicates found\n"
     ]
    }
   ],
   "source": [
    "# === 2.8 Final Validation ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL VALIDATION - CLUSTERING DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Core features for clustering\n",
    "core_features = [\n",
    "    'avg_study_hour',\n",
    "    'study_consistency_std', \n",
    "    'completion_speed',\n",
    "    'avg_exam_score',\n",
    "    'submission_fail_rate',\n",
    "    'retry_count'\n",
    "]\n",
    "\n",
    "print(\"\\nüîç Checking 6 core clustering features:\")\n",
    "all_clean = True\n",
    "for feature in core_features:\n",
    "    if feature in clustering_df.columns:\n",
    "        nan_count = clustering_df[feature].isnull().sum()\n",
    "        inf_count = np.isinf(clustering_df[feature]).sum()\n",
    "        \n",
    "        if nan_count == 0 and inf_count == 0:\n",
    "            print(f\"   ‚úÖ {feature}: Clean\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {feature}: {nan_count} NaN, {inf_count} infinity\")\n",
    "            all_clean = False\n",
    "    else:\n",
    "        print(f\"   ‚ùå {feature}: Column not found!\")\n",
    "        all_clean = False\n",
    "\n",
    "if all_clean:\n",
    "    print(\"\\nüéâ ALL CORE FEATURES ARE READY FOR CLUSTERING!\")\n",
    "    print(f\"   Dataset shape: {clustering_df.shape}\")\n",
    "    \n",
    "    # Show descriptive statistics\n",
    "    print(\"\\nüìä Descriptive statistics for core features:\")\n",
    "    display(clustering_df[core_features].describe())\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  WARNING: Some core features have issues!\")\n",
    "\n",
    "# Duplicate check\n",
    "print(\"\\nüîç DUPLICATE CHECK:\")\n",
    "duplicates = clustering_df[clustering_df.duplicated(subset=['developer_id', 'journey_id'], keep=False)]\n",
    "if len(duplicates) > 0:\n",
    "    print(f\"   ‚ö†Ô∏è  Found {len(duplicates)} duplicate user-journey pairs!\")\n",
    "    display(duplicates[['developer_id', 'journey_id', 'name']].head())\n",
    "else:\n",
    "    print(\"   ‚úÖ No duplicates found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Final clustering dataset: (2008, 23)\n",
      "üíæ Saved: ../data/processed\\clustering_features.csv\n"
     ]
    }
   ],
   "source": [
    "# === 2.9 Select Final Columns & Save ===\n",
    "clustering_final_cols = [\n",
    "    'developer_id', 'journey_id', 'name',\n",
    "    'avg_study_hour', 'study_consistency_std', 'study_consistency_ratio',\n",
    "    'completed_modules', 'total_modules_viewed',\n",
    "    'avg_exam_score', 'exam_pass_rate', 'exam_fail_count',\n",
    "    'avg_submission_rating', 'submission_pass_rate', 'submission_fail_count', 'submission_fail_rate',\n",
    "    'completion_speed', 'retry_count',\n",
    "    'performance_score', 'struggle_score',\n",
    "    'study_time_slot', 'performance_level', 'speed_category', 'difficulty'\n",
    "]\n",
    "\n",
    "clustering_final = clustering_df[clustering_final_cols].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ Final clustering dataset: {clustering_final.shape}\")\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(PROCESSED_DIR, 'clustering_features.csv')\n",
    "clustering_final.to_csv(output_path, index=False)\n",
    "print(f\"üíæ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. DATASET 2: PACE FEATURES (MODEL 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUILDING DATASET 2: PACE FEATURES\n",
      "============================================================\n",
      "üîß Calculating percentile ranks per journey...\n",
      "‚úÖ Pace dataset: (2008, 14)\n",
      "üíæ Saved: ../data/processed\\pace_features.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BUILDING DATASET 2: PACE FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pace_cols = [\n",
    "    'developer_id', 'journey_id', 'name', 'difficulty', 'hours_to_study',\n",
    "    'study_duration', 'completion_speed',\n",
    "    'completed_modules', 'total_modules_viewed',\n",
    "    'avg_study_hour', 'study_consistency_std', 'study_consistency_ratio'\n",
    "]\n",
    "\n",
    "pace_df = clustering_df[pace_cols].dropna(subset=['study_duration']).copy()\n",
    "\n",
    "# Calculate percentile rank per journey\n",
    "print(\"üîß Calculating percentile ranks per journey...\")\n",
    "for journey_id in pace_df['journey_id'].unique():\n",
    "    mask = pace_df['journey_id'] == journey_id\n",
    "    pace_df.loc[mask, 'speed_percentile'] = pace_df.loc[mask, 'study_duration'].rank(pct=True) * 100\n",
    "\n",
    "# Speed category\n",
    "pace_df['speed_category'] = pd.cut(\n",
    "    pace_df['completion_speed'],\n",
    "    bins=[0, 0.7, 1.3, float('inf')],\n",
    "    labels=['Fast (< 70%)', 'Normal (70-130%)', 'Slow (> 130%)']\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Pace dataset: {pace_df.shape}\")\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(PROCESSED_DIR, 'pace_features.csv')\n",
    "pace_df.to_csv(output_path, index=False)\n",
    "print(f\"üíæ Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. DATASET 3: ADVICE CONTEXT (MODEL 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BUILDING DATASET 3: ADVICE CONTEXT\n",
      "============================================================\n",
      "üîß Finding stuck tutorials (last incomplete tutorial)...\n",
      "   ‚úì Found 1161 users with stuck info\n",
      "‚úÖ Advice context dataset: (2008, 18)\n",
      "   ‚úì Users with display names: 2008\n",
      "   ‚úì Users with stuck info: 1161\n",
      "üíæ Saved: ../data/processed\\advice_context.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BUILDING DATASET 3: ADVICE CONTEXT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# === 4.1 Find Stuck Tutorial (As per design doc requirement) ===\n",
    "print(\"üîß Finding stuck tutorials (last incomplete tutorial)...\")\n",
    "\n",
    "stuck_tutorials = df_trackings[df_trackings['completed_at'].isnull()].copy()\n",
    "stuck_tutorials = stuck_tutorials.sort_values('last_viewed', ascending=False)\n",
    "stuck_tutorials = stuck_tutorials.groupby(['developer_id', 'journey_id']).first().reset_index()\n",
    "stuck_tutorials = stuck_tutorials[['developer_id', 'journey_id', 'tutorial_id']]\n",
    "stuck_tutorials.columns = ['developer_id', 'journey_id', 'stuck_tutorial_id']\n",
    "\n",
    "print(f\"   ‚úì Found {len(stuck_tutorials)} users with stuck info\")\n",
    "\n",
    "# === 4.2 Create Advice Context ===\n",
    "advice_cols = [\n",
    "    'developer_id', 'journey_id', 'name',\n",
    "    'avg_study_hour', 'study_time_slot',\n",
    "    'avg_exam_score', 'exam_fail_count',\n",
    "    'avg_submission_rating', 'submission_fail_count',\n",
    "    'completion_speed',\n",
    "    'performance_level', 'struggle_score'\n",
    "]\n",
    "\n",
    "advice_df = clustering_df[advice_cols].copy()\n",
    "\n",
    "# Add speed_category from clustering_df (now it exists!)\n",
    "advice_df['speed_category'] = clustering_df['speed_category']\n",
    "\n",
    "# Add user display name\n",
    "advice_df = advice_df.merge(df_users[['id', 'display_name']], \n",
    "                           left_on='developer_id', right_on='id', how='left')\n",
    "\n",
    "# Add stuck tutorial info\n",
    "advice_df = advice_df.merge(stuck_tutorials, on=['developer_id', 'journey_id'], how='left')\n",
    "\n",
    "# Placeholders for model outputs\n",
    "advice_df['cluster_label'] = None  # Will be populated by Model 1\n",
    "advice_df['pace_insight'] = None   # Will be populated by Model 3\n",
    "\n",
    "print(f\"‚úÖ Advice context dataset: {advice_df.shape}\")\n",
    "print(f\"   ‚úì Users with display names: {advice_df['display_name'].notna().sum()}\")\n",
    "print(f\"   ‚úì Users with stuck info: {advice_df['stuck_tutorial_id'].notna().sum()}\")\n",
    "\n",
    "# Save\n",
    "output_path = os.path.join(PROCESSED_DIR, 'advice_context.csv')\n",
    "advice_df.to_csv(output_path, index=False)\n",
    "print(f\"üíæ Saved: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
